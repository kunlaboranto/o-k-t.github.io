<!DOCTYPE html>
<html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" href="../../css/result.css">

        <title>(sun) vmstat -s</title>
    </head>
    <body>
        <section id="wrap">
            <header>
                <h1 class="logo-title">
                    <span class="main"><img src="../../images/logo_egloos.png" width="105" height="34" alt="이글루스"></span>
                </h1>
                <div class="user-info">
                    <strong class="name">kun</strong> 님 (<strong class="name">okseop7</strong>)
                </div>
            </header>
            <main>
                <article class="post-wrap">
                    <!-- 게시물 정보 : 날짜 -->
                    <div class="post-info">
                        <span class="time">2007-06-18 13:31:32</span>
                    </div>
                    <!-- 게시물 제목 -->
                    <h2 class="post-title">(sun) vmstat -s</h2>
                    <!-- 게시물 본문 -->
                    <div class="post-body">
                        <div class="content"><br><pre>Performance에 관한자료  읽음:592 <br> <br>    - Contents - <br> <br>&lt;1&gt; performance Tuning Overview Summary <br>&lt;2&gt; Performance Tuning <br>    1) CPU (with Mutiprocessors) <br>    2) Kernel <br>&lt;3&gt; References <br> <br> <br> <br>1. Performance Tuning Overview Summary <br> <br>1) Introduction (개요) <br>요즘처럼 S/W, H/W가 하루아침이면 엄청난 발전을 이루어 가면서 발전을하고 있는데,<br>이처럼 Operating system과 Hardware가 변해가는 빠른 속도는 컴퓨터 관련자들 모두에게 <br>커다란 문제가 아닐수 없다.  <br>그러므로 필요한 경우에는 구버전 S/W와 H/W를 예로들어 기본 수준의 튜닝이 시기에 따라서 <br>어느정도 개선되어 왔는가를 보여 주고자 하는것이 목적이다. <br> <br>System Broken Down Info Tuning Layers (시스템의 튜닝 계층) <br>====================================================================== <br> Layers              Variables <br>====================================================================== <br> Source code         Algorithm, Language, Programming model, Compiler <br> Executable          Environment, Filesystem Type <br> Database            Buffer Sizes, Indexing <br> Kernel*             Buffer Sizes, Paging, Tuning, Configuring <br> Memory              Cache Type, Line Size And Miss Cost <br> Disk                DriverAlgorithme, Disk Type, load Balance <br> Windows &amp; Graphics  Window System, Graphics Library, Accelerators <br> CPU*                Processor Implementation <br> Mutiprocessors      Load Balancing, Concurrency, Bus Throughput <br> Network             Protocol, Hardware, Usage Pattern <br>======================================================================= <br> <br>2) Performance Measurement <br>   튜닝의 목적은 대상시스템의 성능을 계측하기위한 일련의 실험을 설계할 필요가 있다. 하지만 <br>   여기서는 그러한 소스코드를 작성해서 측정하는 방법과 실험의 설계, 계측, 시뮬레이션, 성능의 <br>   모델화의 각종 기법에 관하여는 설명하지 않고 실제로 우리가 site에서 간단히 측정 할수있는 <br>   방법을 기술하고자 한다. (CPU Monitoring) <br> <br>3) Quick Referencd for Common Tuning Tips <br> <br>   The First 10 Tuning Steps <br> <br>    (1) The system will usually have a disk bottleneck <br>    (2) You will be told that the system, is not I/O bound <br>    (3) After first pass tuning the system will still have a disk bottleneck! <br>    (4) Poor NFS response times are hard to pin down <br>    (5) Avoid the common memory usage misconceptions (See "Understanding Vmstat Output") <br>    (6) Don't panic when you see page-ins and page-out in vmstat <br>    (7) Look for page scanner activity (See "The Paging Algorithm In Solairs2") <br>    (8) Look for a lang run queue (vmstat procs r) (See "Understanding Vmstat On A Multiprocessor") <br>    (9) Look for processes blocked waiting for I/O (vmstat proc b) <br>   (10) Look for CPU system time dominating user time (See "Tracing In Solaris 2", <br>        "Monitoring The System With Protocol", "Kernel Profiling Using kgmon In Solaris 2") <br> <br> <br>2. Performance Tuning <br> <br>1) CPU (Monitoring) <br> <br>    (1) PS (Report proceses Status) <br>       - Options <br> <br>     -a           Print information about  all  processes  most frequently  requested:   <br>                  all those except process group leaders and processes not  associated <br>                  with a terminal. <br> <br>     -A           Write information for all processes. <br> <br>     -c           Print information in a format that reflects scheduler properties as <br>                  described   in priocntl(1).  The -c option affects the  output  of <br>                  the  -f and -l options, as described below. <br> <br>     -d           Print information about all processes  except session leaders. <br> <br>     -e           Print information  about  every  process  now running. <br> <br>     -f           Generate a full listing.   <br>                  (See below for significance of columns in a full listing.) <br> <br>     -g grplist   List only process data whose group leader's ID number(s) appears in grplist. <br> <br># ps -efl <br> F S      UID   PID  PPID  C PRI NI     ADDR     SZ    WCHAN    STIME TTY      TIME CMD <br>19 T     root     0     0  0   0 SY f0271950      0          15:33:52 ?        0:00 sched <br> 8 S     root     1     0  0  41 20 f5a9bcd8     96 f5a9bea8 15:33:56 ?        0:00 /etc/init - <br>19 S     root     2     0  0   0 SY f5a9b678      0 f0286534 15:33:56 ?        0:00 pageout <br>19 S     root     3     0  0   0 SY f5a9b018      0 f028a74c 15:33:56 ?        0:01 fsflush <br> 8 S     root   367     1  0  41 20 f5aa29a0    328 f5921b14 15:35:55 ?        0:00 /usr/lib/saf/sac -t 300 <br> 8 S     root   372   371  0  49 20 f5aa2340    173 f594b3d6 15:35:55 ?        0:00 vxnotify -f -w 15 <br> 8 S     root   256     1  0  56 20 f5aa1ce0    430 f624befe 15:35:38 ?        0:00 /usr/sbin/inetd -s 8 S     root    12     1  0  41 20 f5aa1680    419 f594b386 15:33:58 ?        0:32 vxconfigd -m boot <br> 8 S     root   239     1  0  41 20 f6132cc8    417 f594b21e 15:35:31 ?        0:00 /usr/sbin/rpcbind <br> 8 S     root   241     1  0  65 20 f6132668    385 f594b1a6 15:35:32 ?        0:00 /usr/sbin/keyserv <br> 8 S     root   247     1  0  47 20 f6132008    422 f594b17e 15:35:32 ?        0:00 /usr/sbin/kerbd <br> 8 S     root   261     1  0  74 20 f61d4990    383 f594b066 15:35:39 ?        0:00 /usr/lib/nfs/lockd 8 S     root   280     1  0  74 20 f61d4330    453 f624bed6 15:35:40 ?        0:00 /usr/lib/autofs/automountd <br> <br>    (2) VMSTAT (Report Virtual Memory statistics) <br>       - Options <br> <br> -c   Report cache flushing statistics.  By  default,  report <br>      the  total  number  of each kind of cache flushed since <br>      boot time.  The types are:  user, context, region, seg- <br>      ment, page, and partial-page. <br> <br> -i   Report the number of interrupts per device. <br> <br> -s   Display the total number of various system events since <br>      boot. <br> <br> -S   Report on swapping rather than paging  activity.   This <br>      option  will  change  two fields in vmstat's ``paging'' <br>      display:  rather than the  ``re''  and  ``mf''  fields, <br>      vmstat  will report ``si'' (swap-ins) and ``so'' (swap- <br>      outs). <br> <br>1&gt; System Events <br> # vmstat -s (show the total of various system events that have taken place <br>             since the system was last booted) <br> <br>        0 swap ins <br>        0 swap outs <br>        0 pages swapped in <br>        0 pages swapped out <br>    36976 <span id="__firefox-findbar-search-id" style="PADDING-RIGHT: 0pt; DISPLAY: inline; PADDING-LEFT: 0pt; PADDING-BOTTOM: 0pt; COLOR: black; PADDING-TOP: 0pt; BACKGROUND-COLOR: yellow">total address trans</span>. faults taken <br>     3905 page ins <br>      135 page outs <br>     6573 pages paged in <br>     1575 pages paged out <br>      791 total reclaims <br>      786 reclaims from free list <br>        0 micro (hat) faults <br>    36976 minor (as) faults <br>     3641 major faults <br>    11172 copy-on-write faults <br>     8806 zero fill page faults <br>     9447 pages examined by the clock daemon <br>        1 revolutions of the clock hand <br>     3492 pages freed by the clock daemon <br>      460 forks <br>       46 vforks <br>      507 execs <br>   153277 cpu context switches <br>   302546 device interrupts <br>    52688 traps <br>   321152 system calls <br>    59129 total name lookups (cache hits 91%) <br>       24 toolong <br>     2581 user   cpu <br>     6329 system cpu <br>   188653 idle   cpu <br>     8366 wait   cpu <br> <br>2&gt; Swapping2&gt; Swapping <br> # vmstat -S (show swapping statistics in addition to paging statistics) <br>     ' si  Number of pages swapped in per second <br>     ' so  Number of whole processes swapped out <br> <br> procs     memory            page            disk          faults      cpu <br> r b w   swap  free  si  so pi po fr de sr s0 s2 sd sd   in   sy   cs us sy id <br> 0 0 0 199188  2204   0   0 11  2  6  0  4  4  0  0  0   46  156   75  1  3 96 <br> <br>3&gt; Cache Flushing <br> # vmstat -c (show cache flushing statistics. It shows the total number of <br>             flush caches since the last boot.) <br>     ' usr  User <br>     ' ctx  Context <br>     ' rgn  Region <br>     ' seg  Segment <br>     ' pag  Page <br>     ' par  Partial-page <br>flush statistics: (totals) <br>     usr     ctx     rgn     seg     pag     par <br>       0       0       0       0       0       0 <br> <br>4&gt; Interrupts <br> # vmstat -i (show interrupts per device) <br>interrupt         total     rate <br>-------------------------------- <br>clock            266951      100 <br>-------------------------------- <br>Total            266951      100 <br> <br>5&gt; Commons <br> # vmstat 5 <br>procs     memory            page            disk          faults      cpu <br> r b w   swap  free  re  mf pi po fr de sr s0 s2 sd sd   in   sy   cs us sy id <br> 0 0 0 199716  2008   0  13  9  2  5  0  3  3  0  0  0   43  141   72  1  2 97 <br> 0 0 0 201788  1092   0  12  0  0  0  0  0  0  0  0  0   21   49   38  2  1 97 <br> 0 0 0 201788  1092   0   0  0  0  0  0  0  0  0  0  0   30   35   27  2  1 97 <br> 0 0 0 201788  1092   0   0  0  0  0  0  0  0  0  0  0   14   35   21  1  0 99 <br> 0 0 0 201788  1092   0   0  0  0  0  0  0  0  0  0  0    8   35   22  2  0 98 <br> 0 0 0 201788  1092   0   0  0  0  0  0  0  0  0  0  0    5   56   36  1  0 99 <br> <br>r = 0                 : CPU Idle (White) <br>0 &lt; (r/ncpus) &lt;= 5    : No Problem (Green) <br>3.0 &lt;= (r/ncpus) &lt;= 5 : CPU Busy (Amber) <br>5.0 &lt;= (r/ncpus)      : CPU Busy (Red) <br> <br>  (3) MPSTAT (Report per-processor statistics) <br>     - options <br>  interval <br>             Report once each interval seconds. <br> <br>  count   Only print count reports. <br> <br># mpstat 5 <br>CPU minf mjf xcal  intr ithr  csw icsw migr smtx  srw syscl  usr sys  wt idl <br>  0   11   1    0   141   34   69   12    0    2    0   133    1   2   3  94 <br>  0   11   0    0   129   27   47    7    0    1    0    44    3   0   0  97 <br>  0    0   0    0   125   25   21    4    0    0    0    28    1   2   0  97 <br>  0    0   0    0   118   18   21    3    0    0    0    28    1   0   0  99 <br>  0    0   0    0   105    4   36    6    0    1    0    49    2   0   0  98 <br> <br>200 &gt; smtx            : No Problem (Green) <br>200 &lt;= smtx &lt; 400     : Mutex Stall (Amber) <br>400 &lt;= smtx           : Mutex Stall (Red) <br> <br> <br> 2) Kernel <br> <br>  (1) 커널의 개요 <br> <br>    1&gt; 화일 제어 시스템 <br>      - 사용자를 위하여 화일을 관리 <br>      - 화일의 공간을 할당 <br>      - 자유 공간을 관리 <br>      - 화일에 대한 접근을 제어하고 데이타를 꺼내온다 <br>      - 커널과 2차 기억 장치 사이의 데이타 흐름을 조절하는 버퍼링 기법을 <br>        이용하여 화일의 데이타를 접근 <br> <br>    2&gt; 프로세스 제어 시스템 <br>      - 프로세스의 동기화, 프로세스간의 통신이나 메모리 관리 <br>      - 프로세스 스케쥴링 담당 <br>      - 프로세스 화일 허가모드는 슈퍼유저라고 불리는 특별한 사용자를 <br>        구분하여 커널 특권 부여 <br> <br>    3&gt; 커널의 배치 <br>      - 커널과 관련된 가상 주소의 매핑은 모든 프로세스와는 독립적인 존재 <br>      - 커널코드와 데이타는 영구적으로 시스템내에 존재 <br>      - 시스템 booting시 커널코드는 메모리에 적재 <br>      - 가상 주소는 매핑하기 위해 필요한 테이블과 레지스터를 설정한다 <br> <br>   4&gt; 시스템 부트및 Init 프로세스 <br>     알고리즘 start         /* 시스템을 기동시키는 프로시쥬어 */ <br>     입력 : 없음 <br>     출력 : 없음 <br>     { <br>            모든 커널 데이타 구조를 초기화 한다; <br>            루트를 의사(pseudo) mount 한다; <br>            프로세스 0의 호나경을 손으로 하나하나 구축; <br>            프로세스 1을 fork; <br>            { <br>                     /* 프로세스 1 */ <br>                     영역을 할당; <br>                     영역을 init의 주소공간을 부착(attach); <br>                     복사하려는 코드를 넣을수 있도록 영역을 키움; <br>                     Init를 exec할수 있도록 커널 공간으로부터 init 사용자 <br>                     공간으로 코드를 복사; <br>                     모드를 변경:커널로부터 사용자 모드로 복귀; <br>                     /* Init는 이 지점에 결코 도달하지 않는다-위의 모드변경 <br>                     결과로, Init는 /etc/init를 exec하고 시스템 호출을 하는 <br>                     면에 있어, "정규적"인 사용자 프로세스가 된다 <br>                     */ <br>            } <br>            /* 프로세스 0이 여기서 계속 */ <br>            커널 프로세스들을 fork; <br>            /* 프로세스 0은 프로세스의 주소공간을 메인 메모리와 스왑 장치에 <br>               할당하는 것을 관리하기 위해 스와퍼를 호출한다 <br>               이것은 무한 루프이다;프로세스 0은 할일이 없으면 항상 이 루프에서               잠잔다 <br>            */ <br>            스와퍼 알고리즘의 코드를 수행; <br>     } <br>------------------------------------------------------------------------------- <br>     알고리즘 init         /* init프로세스, 시스템의 1번 프로세스이다 */ <br>     입력 : 없음 <br>     출력 : 없음 <br>     { <br>            fd=open("/etc/inittab",O_RDONLY); <br>            while (line_read(fd, buffer)) <br>            { <br>                     /* 화일의 각 행을 읽는다 */ <br>                     if(호출된 상태! = buffer의 상태) <br>                            continue;        /* while 루프로 되돌아감 */ <br>                     /* 상태가 일치함 */ <br>                     if(fork() == 0) <br>                     { <br>                            execl("buffer에 지정된 프로세스"); <br>                            exit(); <br>                     } <br>                     while ((id=wait(int *) 0))! = -1) <br>                     { <br>                             /* 낳은 (spawn) 자식이 죽었는디 여기서 검사 */ <br>                             /* 자식 프로세스를 다시 낳을지를 고려 */ <br>                             /* 그렇지 않으면, 단순히 계속 */ <br>             } <br>       } <br> <br>5&gt; 커널 parameters <br>------------------------------------------------------------------------------- 커널자원           튜닝 가능항목              디폴트 설정 <br>------------------------------------------------------------------------------- 콜 아웃             ncallout                 16+max_nrpocs <br> i node              ufs_ninode               max_nprocs + 16 + maxusers + 64 <br> 네임 캐쉬           ncsize                   nax_nprocs + 16 + maxusers + 64 <br> 프로세스            max_nprocs               10 + 16 * maxusers <br> 쿼터테이블          ndquot                   (maxusers *NMOUNT)/4 + max_nprocs <br> 사용자프로세스      maxuproc                 max_nprocs -5 <br>------------------------------------------------------------------------------- <br> <br> (2) Solaris 2.X maxusers 설정값 <br>    - maxuser는 시스템 내에 내장된 RAM의 메가바이트수와 같은 값으로 설정 <br>    - maxuser수는 커널이 부팅시간에 사용되는 약 2MB를 포함하지 않으면 physmem <br>      에 기초한다 <br>    - 하한값은 8이며 자동설정에서의 상한값은 1024(RAM이 1GB 이상인 경우) 이다 <br>    - 수동으로 설정한 값은 체크되어 2048 이하로 제한 <br> <br> (3) 테이블 사이즈와 커널의 메모리 할당 검사 <br>    - 커널은 필요에 따라 메모리를 글로벌 프리 리스트에서 동적으로 할당 <br> # sar -v 1 <br>SunOS HongSW 5.5 Generic sun4m    06/29/96 <br> <br>09:59:52  proc-sz    ov  inod-sz    ov  file-sz    ov   lock-sz <br>09:59:53   50/474     0 1297/1297    0  323/323     0    0/0 <br> <br> # sar -k 1 <br>SunOS HongSW 5.5 Generic sun4m    07/02/96 <br> <br>06:59:26 sml_mem   alloc  fail  lg_mem   alloc  fail  ovsz_alloc  fail <br>06:59:27  962560  791556     0 2400256 2204272     0     2142208     0 <br> <br> (4) 디렉토리 탐색캐쉬(dnlc) <br>    - maxuser를 기반으로하여 크기 결정 <br>    - 캐쉬 사이즈가 크면 클라이언트 NFS 서버의 부하감소 <br>    - NFS 서버의 벤치마크에서는 커널 메모리의 용량은 16,000으로 설정되며 또한 <br>      maxuser = 2048 에서는 34906으로 인정 <br> # vmstat -s <br>  0 swap ins <br>        0 swap outs <br>        0 pages swapped in <br>        0 pages swapped out <br>   152546 <span id="__firefox-findbar-search-id" style="PADDING-RIGHT: 0pt; DISPLAY: inline; PADDING-LEFT: 0pt; PADDING-BOTTOM: 0pt; COLOR: black; PADDING-TOP: 0pt; BACKGROUND-COLOR: yellow">total address trans</span>. faults taken <br>     4844 page ins <br>     1033 page outs <br>     7952 pages paged in <br>     3365 pages paged out <br>     1609 total reclaims <br>     1598 reclaims from free list <br>        0 micro (hat) faults <br>   152546 minor (as) faults <br>     4555 major faults <br>    43797 copy-on-write faults <br>    24943 zero fill page faults <br>    12374 pages examined by the clock daemon <br>        2 revolutions of the clock hand <br>     6155 pages freed by the clock daemon <br>     1971 forks <br>      110 vforks <br>     1916 execs <br>  4157796 cpu context switches <br> 34296735 device interrupts <br>   212208 traps <br>  1416794 system calls <br>   190345 total name lookups (cache hits 95%) <br>       24 toolong <br>     6271 user   cpu <br>    29261 system cpu <br> 31448842 idle   cpu <br>    15157 wait   cpu <br> <br> (5) inode 캐쉬 <br>    - 화일 시스템내의 엔티티의 대한 조작이 실행될 때에는 메모리 상주 inode 사용 <br>    - inode는 다시 필요해진 경우에 대비하여 캐쉬에 기록 <br>    - 시스템이 캐쉬라는 액티브한 inode와 비액티브한 inode의 상한수는 ufs-ninode      에 의해서 설정 <br>    - 각 node는 lg-mem풀에서 512바이트의 커널 메모리 사용 <br> <br> (6) 버퍼 캐쉬 <br>    - nbuf : 페이지 사이즈의 버퍼가 몇개 할당되었는지를 계속 기록 <br>    - p-nbuf : 한 벌에 할당된 새로운 버퍼의 수를 정리 <br>    - bufhwm : 버퍼에 할당된 메모리량을 튜닝하기 위한 변수 (KB단위로 지정) <br> # sar -b 5 <br>SunOS HongSW 5.5 Generic sun4m    07/02/96 <br> <br>07:13:59 bread/s lread/s %rcache bwrit/s lwrit/s %wcache pread/s pwrit/s <br>07:14:00       0       0     100       0       0     100       0       0 <br> <br> (7) vmstat 출력 <br>    - Sun System에 있어서 페이징 상황을 Monitoring <br> # vmstat 5 <br> procs     memory            page            disk          faults      cpu <br> r b w   swap  free  re  mf pi po fr de sr s0 s2 sd sd   in   sy   cs us sy id <br> 0 0 0  37576  1384   0   0  0  0  0  0  0  0  0  0  0    8    4   13  0  0 100 <br> 0 0 0 199960  1044   0  12  0  0  0  0  0  0  0  0  0   13   60   45  1  1 98 <br> 0 0 0 199960  1044   0   0  0  0  0  0  0  0  0  0  0    9   32   30  0  0 100 <br> 0 0 0 199960  1044   0   0  0  0  0  0  0  0  0  0  0    4   42   23  1  0 99 <br> 0 0 0 199960  1044   0   0  0  0  0  0  0  0  0  0  0    1   42   25  1  0 99 <br> 0 0 0 199960  1044   0   0  0  0  0  0  0  0  0  0  0    2   42   23  1  0 99 <br> 0 0 0 199960  1044   0   0  0  0  0  0  0  0  0  0  0    2   42   23  1  0 99 <br> 0 0 0 199960  1044   0   0  0  0  0  0  0  0  0  0  0    5   42   27  1  0 99 <br> 0 0 0 199960  1044   0   0  0  0  0  0  0  0  0  0  0    9   42   23  1  0 99 <br> <br> r : 대기 프로세서 <br> <br> (8) 튜닝 파라미터 <br> <br>* phymem <br>   : 이 값은 사용가능한 물리 메모리의 메이지 수로 설정된다. Solaris 2.2에서는 <br>     maxusers의 값은 physmem의 값에 기초하여 계산된다. 시스템의 성능을 조시하기     위한 시스템의 메모리를 적게 하여 실행 테스트를 하려는 경우에는 /etc/system     에서 phymem을 설정하여 재부팅하면 시스템이 RAM 전부를 사용하지 않도록 <br>     할수 있다. 그러므로 phymem에서 메모리를 적게 한 시스템에서 대량의 페이징을 <br>     실행한 경우의 성능은 RAM을 물리적으로 제거하여 대량의 페이징을 실행한 <br>     경우와는 다른것이 된다 <br> <br>* minfree <br>   : minfree는 phymem을 64로 나눈값(phymem/64)으로 설정된다. 커널은 minfree를 <br>     아래의 목적으로 사용한다. 작은 프로그램을 실행 할때는 freemem이 minfree <br>     미만으로 되지않는한 프로그램 전체가 한번에 로드되어 세밀한 페이징은 <br>     되지 않는다 <br>   - 기록할때 복사 조작을 하는 동안 freemem이 minfree미만의 경우에는 오리지날 <br>     페이지를 스틸하여 복사를 공급할수 있다 <br>   - freemem이 minfree 미만의 경우에는 입,출력 읽기의 클러스터화가 실행되지 <br>     않게 된다 <br>   - 스케쥴러는 사용가능한 메모리가 minfree + tune_t_gpgsol에 채워지지 않는 경 <br>     우에는 프로세서를 스왑인 하지 않는다. 이러한 상태가 발생하는 경우에는 <br>     매우 드물다 <br> <br>* desfree <br>   : desfree는 phymem을 32로 나눈 값으로 설정된다. 커널은 desfree를 아래의 목적 <br>     으로 사용한다. <br>   - 100Hz의 클럭 루틴 동안에 freemem이 lostfree미만으로 되어 있지 않은지의 <br>     여부를 확인 하는 테스트가 1초당 4회 이루어 진다. 미만으로 되어 있는 경우 <br>     에는 페이지 아웃 데몬으로 기동 콜이 송신된다 <br>   - lostfree는 주사율 변경의 기준선이 된다. freemem이 lostfree와 똑같은 경우, <br>     주사율은 slowscan으로 설정된다 <br>   - freemem이 lostfree미만의 경우, 커널은 페이지 사이즈의 일시 버퍼 일부를 <br>     장래의 사용에 대비하여 유지하는 대신에 해방하려고 한다 <br> <br>* fastscan <br>   : fastscan은 phymem의 절반 값으로 설정된다. 이것은 주사율의 변경에 있어서 <br>     freemem이 0인 경우의 가공 주사율로써 사용된다 <br> <br>* slowsacn <br>   : 사용 가능한 메모리량이 lostfree와 똑같을때 알고리즘이 1초간 조사하는 페이 <br>     지 수이다. fastscan을 10으로 나눈 수로 설정되어 있다. 빈 메모리량이 <br>     lostfree에서 0에 가까와 짐에 따라 1초간의 주사율 수는 slowscan으로 부터 <br>     fastscan으로 비례적으로 상승한다 <br> <br>* maxpqio <br>   : 시스템이 스케쥴러 1초당의 페이지 아웃 입,출력 조작의 최대 수이다 <br>     디폴트는 40페이지/초로 단일 3600rpm 디스크로의 랜덤 엑세스가 과잉으로 <br>     되는 것을 피하기 위하여 회전율의 3/2로 설정되어 있다. 더구나 많은 디스크 <br>     또는 더욱 고속의 디스크를 스왑 공간으로 사용하는 경우에는 더욱 큰 수를 <br>     설정할 수 있다. 현재는 많은 시스템이 5400rpm의 디스크를 사용하고 있다 <br>     maxpqio의 변경은 재부팅 후에 유효해진다. 즉 실행중인 시스템에서는 <br>     변경되지 않는다 <br> <br>* handspred <br>   : handspred는 phymem과 페이지 사이즈를 곱하여 나눈 값으로 설정된다 <br>     그러나 이 값은 초기화중에 fastscan이상의 크기로 증가된다 <br>     즉 phymem과 페이지 사이즈를 서로 곱하여 2로 나눈값으로 설정된다.</pre><!-- //포스팅 --></div>
                        <div class="post-footer">
                            <button class="btn" onclick="button_click();">목록</button>
                        </div>
                    </div>
                </article>
            </main>
        </section>

        <script src="https://code.jquery.com/jquery-3.5.1.js"></script>

        <script>
            function button_click() {
                if(history.length > 1) {
                    history.back();
                } else {
                    document.location.href = "../../블로그포스트목록.html";
                }
            }
        </script>
    </body>
</html>
